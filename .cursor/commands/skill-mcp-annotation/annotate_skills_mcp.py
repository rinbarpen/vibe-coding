import os
import json
import re
from pathlib import Path

WORKSPACE_ROOT = Path(__file__).parents[3]
SKILLS_DIR = WORKSPACE_ROOT / "skills"
# MCP è·¯å¾„å¯èƒ½éœ€è¦æ ¹æ®å®é™…ç¯å¢ƒè°ƒæ•´ï¼Œè¿™é‡Œä½¿ç”¨ä¹‹å‰æ¢ç´¢åˆ°çš„è·¯å¾„
MCPS_DIR = Path("/home/rczx/.cursor/projects/home-rczx-workspace-rinbarpen-vibe-coding/mcps")

LANGS = {
    'cn': {
        'title': 'Skills & MCP æ ‡æ³¨ç´¢å¼•',
        'skills': 'æŠ€èƒ½ (Skills)',
        'mcps': 'MCP æœåŠ¡å™¨ (MCP Servers)',
        'path': 'è·¯å¾„',
        'desc': 'ç®€ä»‹',
        'usage': 'ä½¿ç”¨åœºæ™¯',
        'see_desc': 'è§ç®€ä»‹',
        'file_name': 'ANNOTATIONS.md'
    },
    'en': {
        'title': 'Skills & MCP Annotations Index',
        'skills': 'Skills',
        'mcps': 'MCP Servers',
        'path': 'Path',
        'desc': 'Description',
        'usage': 'Usage',
        'see_desc': 'See description',
        'file_name': 'ANNOTATIONS_EN.md'
    }
}

def extract_skill_info(skill_path):
    skill_md = skill_path / "SKILL.md"
    agents_md = skill_path / "AGENTS.md"
    
    target_file = None
    if skill_md.exists():
        target_file = skill_md
    elif agents_md.exists():
        target_file = agents_md
        
    if not target_file:
        return None
    
    content = target_file.read_text(encoding="utf-8")
    
    # Try to extract YAML frontmatter manually to avoid PyYAML dependency
    name = skill_path.name
    description = ""
    
    yaml_match = re.match(r"^---\s*\n(.*?)\n---\s*\n", content, re.DOTALL)
    if yaml_match:
        yaml_content = yaml_match.group(1)
        name_match = re.search(r"^name:\s*(.*)$", yaml_content, re.MULTILINE)
        desc_match = re.search(r"^description:\s*(.*)$", yaml_content, re.MULTILINE)
        if name_match:
            name = name_match.group(1).strip().strip('"').strip("'")
        if desc_match:
            description = desc_match.group(1).strip().strip('"').strip("'")
            
    if not description:
        # Fallback: find first # header and first paragraph
        header_match = re.search(r"^#\s+(.*)$", content, re.MULTILINE)
        if header_match:
            name = header_match.group(1).strip()
        
        # Find first non-empty line after header
        body = re.sub(r"^---.*?---\s*", "", content, flags=re.DOTALL)
        body = re.sub(r"^#.*$", "", body, flags=re.MULTILINE)
        paragraphs = [p.strip() for p in body.split("\n") if p.strip()]
        if paragraphs:
            description = paragraphs[0]

    return {
        "name": name,
        "path": str(skill_path.relative_to(WORKSPACE_ROOT)),
        "description": description
    }

def extract_mcp_info(mcp_path):
    metadata_file = mcp_path / "SERVER_METADATA.json"
    instructions_file = mcp_path / "INSTRUCTIONS.md"
    
    if not metadata_file.exists():
        return None
        
    try:
        metadata = json.loads(metadata_file.read_text(encoding="utf-8"))
        name = metadata.get("serverName", mcp_path.name)
    except Exception:
        name = mcp_path.name
        
    description = ""
    if instructions_file.exists():
        content = instructions_file.read_text(encoding="utf-8")
        # Get first paragraph
        paragraphs = [p.strip() for p in content.split("\n") if p.strip()]
        if paragraphs:
            description = paragraphs[0]
            
    return {
        "name": name,
        "path": str(mcp_path),
        "description": description
    }

def generate_markdown(skills_data, mcps_data, lang='cn'):
    labels = LANGS[lang]
    output = [f"# {labels['title']}\n"]
    
    output.append(f"## {labels['skills']}\n")
    for s in sorted(skills_data, key=lambda x: x['name']):
        output.append(f"### {s['name']}")
        output.append(f"- **{labels['path']}**: `{s['path']}`")
        output.append(f"- **{labels['desc']}**: {s['description']}")
        
        usage = s['description'] if "Use" in s['description'] or "ä½¿ç”¨" in s['description'] else labels['see_desc']
        output.append(f"- **{labels['usage']}**: {usage}")
        output.append("")

    output.append(f"## {labels['mcps']}\n")
    for m in sorted(mcps_data, key=lambda x: x['name']):
        output.append(f"### {m['name']}")
        output.append(f"- **{labels['path']}**: `{m['path']}`")
        output.append(f"- **{labels['desc']}**: {m['description']}")
        
        usage = m['description'] if "Use" in m['description'] or "ä½¿ç”¨" in m['description'] else labels['see_desc']
        output.append(f"- **{labels['usage']}**: {usage}")
        output.append("")
    
    return "\n".join(output)

def get_counts():
    sci_count = 0
    sci_dir = SKILLS_DIR / "claude-scientific-skills" / "scientific-skills"
    if sci_dir.exists():
        sci_count = len([d for d in sci_dir.iterdir() if d.is_dir()])
        
    ui_styles_count = 0
    ui_styles_file = SKILLS_DIR / "ui-ux-pro-max-skill" / "skills" / "ui-ux-pro-max" / "data" / "styles.csv"
    if ui_styles_file.exists():
        try:
            with open(ui_styles_file, 'r', encoding='utf-8') as f:
                ui_styles_count = len(f.readlines()) - 1
        except Exception:
            ui_styles_count = 57 # Fallback
            
    anthropic_count = 0
    anth_dir = SKILLS_DIR / "anthropics" / "skills"
    if anth_dir.exists():
        anthropic_count = len([d for d in anth_dir.iterdir() if d.is_dir()])
        
    return {
        'scientific': sci_count,
        'ui_styles': ui_styles_count,
        'anthropic': anthropic_count
    }

def update_readmes(counts):
    # Chinese README
    readme_cn = f"""# vibe-coding

æœ¬é¡¹ç›®æ˜¯ä¸€ä¸ªé›†æˆäº†å¤šç§ä¸“ä¸š AI æŠ€èƒ½ (Skills) çš„å·¥å…·åº“ï¼Œæ—¨åœ¨å°† Claude è½¬åŒ–ä¸ºå…·å¤‡å¤šé¢†åŸŸä¸“ä¸šçŸ¥è¯†çš„æ™ºèƒ½åŠ©æ‰‹ã€‚é€šè¿‡é›†æˆç§‘å­¦ç ”ç©¶ã€è®¾è®¡ç¾å­¦å’Œå¼€å‘è€…å·¥å…·ï¼Œæ‚¨å¯ä»¥ç›´æ¥åœ¨å¯¹è¯ä¸­æ‰§è¡Œå¤æ‚çš„ä¸“ä¸šä»»åŠ¡ã€‚

---

## ğŸš€ æ ¸å¿ƒæŠ€èƒ½è¯¦ç»†ä»‹ç»

### 1. ğŸ§¬ ç§‘å­¦ç ”ç©¶ä¸ååŒå®éªŒå®¤ (Scientific Research)
åŸºäº **[Claude Scientific Skills](skills/claude-scientific-skills)** (K-Dense AI)ï¼ŒåŒ…å« **{counts['scientific']}+** ä¸ªæ·±åº¦é›†æˆçš„ç§‘ç ”æŠ€èƒ½ã€‚

*   **ç”Ÿç‰©ä¿¡æ¯å­¦ä¸åŸºå› ç»„å­¦**: åºåˆ—åˆ†æã€å•ç»†èƒ RNA-seq å¤„ç†ã€åŸºå› è°ƒèŠ‚ç½‘ç»œã€å˜å¼‚æ³¨é‡Šã€‚
*   **åŒ–å­¦ä¿¡æ¯å­¦ä¸è¯ç‰©å‘ç°**: åˆ†å­å±æ€§é¢„æµ‹ã€è™šæ‹Ÿç­›é€‰ã€ADMET åˆ†æã€åˆ†å­å¯¹æ¥ (Molecular Docking)ã€‚
*   **è›‹ç™½è´¨ç»„å­¦**: LC-MS/MS æ•°æ®å¤„ç†ã€è‚½æ®µé‰´å®šã€è›‹ç™½è´¨å®šé‡ã€‚
*   **ä¸´åºŠç ”ç©¶ä¸ç²¾å‡†åŒ»ç–—**: ä¸´åºŠè¯•éªŒåˆ†æã€è¯ç‰©å®‰å…¨è¯„ä¼°ã€æ²»ç–—æ–¹æ¡ˆè§„åˆ’ã€‚
*   **åŒ»ç–—å½±åƒ**: DICOM å¤„ç†ã€å…¨åˆ‡ç‰‡å›¾åƒåˆ†æã€æ•°å­—åŒ–ç—…ç†æµã€‚
*   **ç‰©ç†ä¸ææ–™ç§‘å­¦**: æ™¶ä½“ç»“æ„åˆ†æã€ç›¸å›¾è®¡ç®—ã€å¤©æ–‡æ•°æ®è½¬æ¢ã€‚

### 2. ğŸ¨ UI/UX è®¾è®¡æ™ºèƒ½ (Design Intelligence)
ç»“åˆ **[UI-UX Pro Max](skills/ui-ux-pro-max-skill)** ä¸ Anthropic å®˜æ–¹è®¾è®¡æŠ€èƒ½ã€‚

*   **æ™ºèƒ½è®¾è®¡ç³»ç»Ÿç”Ÿæˆ**: è‡ªåŠ¨åˆ†æé¡¹ç›®éœ€æ±‚å¹¶ç”Ÿæˆå®Œæ•´çš„è§†è§‰è§„èŒƒã€‚
*   **{counts['ui_styles']}+ UI é£æ ¼åº“**: æ”¯æŒ Glassmorphism (æ¯›ç»ç’ƒ), Neumorphism (æ–°æ‹Ÿæ€), Minimalism ç­‰æµè¡Œé£æ ¼ã€‚
*   **[Frontend Design](skills/anthropics/skills/frontend-design)**: éµå¾ªä¸“ä¸šè®¾è®¡ç¾å­¦çš„ç•Œé¢ç»„ä»¶ç”Ÿæˆï¼Œå‘Šåˆ«â€œAI å‘³â€åè¶³çš„å¹³åº¸è®¾è®¡ã€‚
*   **[Theme Factory](skills/anthropics/skills/theme-factory)**: é¢„è®¾å¤šç§è¡Œä¸šä¸»é¢˜ï¼ˆå¦‚ Arctic Frost, Midnight Galaxyï¼‰ï¼Œä¸€é”®åˆ‡æ¢è§†è§‰é£æ ¼ã€‚
*   **[Algorithmic Art](skills/anthropics/skills/algorithmic-art)**: åŸºäº p5.js çš„ç”Ÿæˆè‰ºæœ¯åˆ›ä½œã€‚

### 3. ğŸ“„ ç”Ÿäº§åŠ›ä¸åŠå…¬è‡ªåŠ¨åŒ– (Enterprise Productivity)
æ·±åº¦é›†æˆ **[Anthropic Official Document Skills](skills/anthropics)**ï¼ŒåŒ…å« **{counts['anthropic']}+** ä¸ªå®˜æ–¹æ–‡æ¡£å¤„ç†æŠ€èƒ½ã€‚

*   **[Word (docx)](skills/anthropics/skills/docx)**: é«˜çº§æ–‡æ¡£åˆ›å»ºã€ä¿®è®¢è¿½è¸ªã€å¤æ‚æ ¼å¼å¤„ç†ã€‚
*   **[Excel (xlsx)](skills/anthropics/skills/xlsx)**: è‡ªåŠ¨åŒ–æ•°æ®é€è§†ã€å…¬å¼ç”Ÿæˆä¸å¤§è§„æ¨¡è¡¨æ ¼åˆ†æã€‚
*   **[PowerPoint (pptx)](skills/anthropics/skills/pptx)**: ç»“æ„åŒ–å¹»ç¯ç‰‡ç”Ÿæˆã€å†…å®¹å¸ƒå±€ä¼˜åŒ–ã€‚
*   **[PDF Master](skills/anthropics/skills/pdf)**: æå–è¡¨å•å­—æ®µã€PDF æ ‡æ³¨å¡«å……ã€å›¾åƒè½¬æ¢ã€‚
*   **[Internal Comms](skills/anthropics/skills/internal-comms)**: ä¼ä¸šæ–°é—»ç¨¿ã€çŠ¶æ€æŠ¥å‘Šã€FAQ ç¼–å†™æ¨¡æ¿ã€‚

### 4. ğŸ› ï¸ å¼€å‘è€…å¢å¼ºå·¥å…· (Developer Empowerment)
ä¸“ä¸ºç¨‹åºå‘˜è®¾è®¡çš„è‡ªåŠ¨åŒ–æµï¼Œæå‡å¼€å‘æ•ˆç‡ã€‚

*   **[MCP Builder](skills/anthropics/skills/mcp-builder)**: è‡ªåŠ¨ç”Ÿæˆç¬¦åˆ Model Context Protocol è§„èŒƒçš„æœåŠ¡å™¨ä»£ç ï¼ˆNode/Pythonï¼‰ã€‚
*   **[Web Artifacts Builder](skills/anthropics/skills/web-artifacts-builder)**: å¿«é€Ÿæ„å»º React + Tailwind + Lucide çš„äº¤äº’å¼ç»„ä»¶é¢„è§ˆã€‚
*   **[Webapp Testing](skills/anthropics/skills/webapp-testing)**: ä½¿ç”¨ Playwright è‡ªåŠ¨ç¼–å†™å¹¶è¿è¡Œæœ¬åœ°åº”ç”¨æµ‹è¯•ç”¨ä¾‹ã€‚
*   **[Skill Creator](skills/anthropics/skills/skill-creator)**: éµå¾ª Agent Skills è§„èŒƒï¼Œè¾…åŠ©æ‚¨å¼€å‘å’Œæ ¡éªŒè‡ªå®šä¹‰æŠ€èƒ½ã€‚

---

## ğŸ“‚ æŠ€èƒ½ä¸ MCP ç´¢å¼• (Index)

ä¸ºäº†æ–¹ä¾¿æŸ¥æ‰¾å’Œä½¿ç”¨ï¼Œæˆ‘ä»¬æä¾›äº†è¯¦ç»†çš„æŠ€èƒ½ä¸ MCP æœåŠ¡å™¨æ ‡æ³¨ç´¢å¼•ï¼š
- ğŸ‡¨ğŸ‡³ [ä¸­æ–‡æ ‡æ³¨ç´¢å¼•](skills/ANNOTATIONS.md)
- ğŸ‡ºğŸ‡¸ [English Annotations Index](skills/ANNOTATIONS_EN.md)

## ğŸ› ï¸ å¦‚ä½•ä½¿ç”¨

1.  **åŠ è½½æŠ€èƒ½**: åœ¨æ”¯æŒ Skills çš„ç¯å¢ƒï¼ˆå¦‚ Claude Code æˆ– Claude.aiï¼‰ä¸­å¼•ç”¨å¯¹åº”ç›®å½•ã€‚
2.  **ç›´æ¥è§¦å‘**: 
    *   *â€œä½¿ç”¨ç§‘å­¦æŠ€èƒ½åˆ†æè¿™æ®µ DNA åºåˆ—...â€*
    *   *â€œä½¿ç”¨ UI-UX æŠ€èƒ½ä¸ºæˆ‘çš„é‡‘è App ç”Ÿæˆä¸€ä¸ªè®¾è®¡ç³»ç»Ÿ...â€*
    *   *â€œä½¿ç”¨ Word æŠ€èƒ½åŸºäºè¿™ä¸ªå¤§çº²ç”Ÿæˆä¸€ä»½å­£åº¦æŠ¥å‘Š...â€*

## ğŸ“œ è®¸å¯è¯

æœ¬é¡¹ç›®é›†æˆçš„æŠ€èƒ½åº“åˆ†åˆ«éµå¾ªå…¶åŸä½œè€…çš„å¼€æºè®¸å¯ï¼š
- Anthropic Skills: Apache 2.0 / Source-available
- Scientific Skills: MIT
- UI-UX Pro Max: MIT
"""
    WORKSPACE_ROOT.joinpath("README.md").write_text(readme_cn, encoding="utf-8")

    # English README
    readme_en = f"""# vibe-coding

This project is a toolkit that integrates various professional AI Skills, aiming to transform Claude into an intelligent assistant with multi-domain professional knowledge. By integrating scientific research, design aesthetics, and developer tools, you can perform complex professional tasks directly in the conversation.

---

## ğŸš€ Core Skills Detailed Introduction

### 1. ğŸ§¬ Scientific Research & Collaborative Lab
Based on **[Claude Scientific Skills](skills/claude-scientific-skills)** (K-Dense AI), containing **{counts['scientific']}+** deeply integrated research skills.

*   **Bioinformatics & Genomics**: Sequence analysis, single-cell RNA-seq processing, gene regulatory networks, variant annotation.
*   **Cheminformatics & Drug Discovery**: Molecular property prediction, virtual screening, ADMET analysis, molecular docking.
*   **Proteomics**: LC-MS/MS data processing, peptide identification, protein quantification.
*   **Clinical Research & Precision Medicine**: Clinical trial analysis, drug safety assessment, treatment planning.
*   **Medical Imaging**: DICOM processing, whole-slide image analysis, digital pathology workflows.
*   **Physics & Materials Science**: Crystal structure analysis, phase diagram calculation, astronomical data conversion.

### 2. ğŸ¨ UI/UX Design Intelligence
Combines **[UI-UX Pro Max](skills/ui-ux-pro-max-skill)** with Anthropic official design skills.

*   **Intelligent Design System Generation**: Automatically analyze project requirements and generate complete visual specifications.
*   **{counts['ui_styles']}+ UI Style Library**: Supports Glassmorphism, Neumorphism, Minimalism, and other popular styles.
*   **[Frontend Design](skills/anthropics/skills/frontend-design)**: Generate interface components following professional design aesthetics, avoiding mediocre "AI-flavored" designs.
*   **[Theme Factory](skills/anthropics/skills/theme-factory)**: Preset multiple industry themes (e.g., Arctic Frost, Midnight Galaxy) for one-click visual style switching.
*   **[Algorithmic Art](skills/anthropics/skills/algorithmic-art)**: Generative art creation based on p5.js.

### 3. ğŸ“„ Enterprise Productivity & Office Automation
Deeply integrates **[Anthropic Official Document Skills](skills/anthropics)**, containing **{counts['anthropic']}+** official document processing skills.

*   **[Word (docx)](skills/anthropics/skills/docx)**: Advanced document creation, revision tracking, complex formatting.
*   **[Excel (xlsx)](skills/anthropics/skills/xlsx)**: Automated pivot tables, formula generation, and large-scale spreadsheet analysis.
*   **[PowerPoint (pptx)](skills/anthropics/skills/pptx)**: Structured slide generation, content layout optimization.
*   **[PDF Master](skills/anthropics/skills/pdf)**: Extract form fields, PDF annotation filling, image conversion.
*   **[Internal Comms](skills/anthropics/skills/internal-comms)**: Corporate press releases, status reports, FAQ writing templates.

### 4. ğŸ› ï¸ Developer Empowerment
Automated workflows designed for programmers to enhance development efficiency.

*   **[MCP Builder](skills/anthropics/skills/mcp-builder)**: Automatically generate server code (Node/Python) following Model Context Protocol specifications.
*   **[Web Artifacts Builder](skills/anthropics/skills/web-artifacts-builder)**: Quickly build interactive component previews with React + Tailwind + Lucide.
*   **[Webapp Testing](skills/anthropics/skills/webapp-testing)**: Automatically write and run local application test cases using Playwright.
*   **[Skill Creator](skills/anthropics/skills/skill-creator)**: Assist in developing and validating custom skills following the Agent Skills specification.

---

## ğŸ“‚ Skills & MCP Index

For convenience, we provide detailed annotation indices for skills and MCP servers:
- ğŸ‡¨ğŸ‡³ [Chinese Annotations Index](skills/ANNOTATIONS.md)
- ğŸ‡ºğŸ‡¸ [English Annotations Index](skills/ANNOTATIONS_EN.md)

## ğŸ› ï¸ How to Use

1.  **Load Skills**: Reference the corresponding directory in an environment that supports Skills (e.g., Claude Code or Claude.ai).
2.  **Trigger Directly**: 
    *   *"Use scientific skills to analyze this DNA sequence..."*
    *   *"Use UI-UX skills to generate a design system for my finance app..."*
    *   *"Use Word skills to generate a quarterly report based on this outline..."*

## ğŸ“œ License

The skill libraries integrated in this project follow their respective original authors' open-source licenses:
- Anthropic Skills: Apache 2.0 / Source-available
- Scientific Skills: MIT
- UI-UX Pro Max: MIT
"""
    WORKSPACE_ROOT.joinpath("README_EN.md").write_text(readme_en, encoding="utf-8")
    print("Updated README.md and generated README_EN.md")

def main():
    skills_data = []
    if SKILLS_DIR.exists():
        # é€’å½’æŸ¥æ‰¾åŒ…å« SKILL.md æˆ– AGENTS.md çš„ç›®å½•
        for root, dirs, files in os.walk(SKILLS_DIR):
            if "SKILL.md" in files or "AGENTS.md" in files:
                info = extract_skill_info(Path(root))
                if info:
                    skills_data.append(info)
                    # æ‰¾åˆ°åä¸å†æ·±å…¥å­ç›®å½•ï¼ˆå‡è®¾ä¸€ä¸ªç›®å½•å°±æ˜¯ä¸€ä¸ª skillï¼‰
                    dirs.clear()

    mcps_data = []
    if MCPS_DIR.exists():
        for item in MCPS_DIR.iterdir():
            if item.is_dir():
                info = extract_mcp_info(item)
                if info:
                    mcps_data.append(info)

    # Generate for both languages
    for lang_code in LANGS:
        content = generate_markdown(skills_data, mcps_data, lang=lang_code)
        file_path = SKILLS_DIR / LANGS[lang_code]['file_name']
        file_path.write_text(content, encoding="utf-8")
        print(f"Generated {file_path}")

    # Update READMEs
    counts = get_counts()
    update_readmes(counts)

if __name__ == "__main__":
    main()
